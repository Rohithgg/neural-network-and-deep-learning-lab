{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# week 7\n",
    "## Recurrent neural network (RNNs)\n",
    "### part 3: Analyze the vanishing gradient problem in RNNs."
   ],
   "id": "a748d7a57d83a690"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:32:32.113970Z",
     "start_time": "2025-03-12T10:32:28.875230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, BatchNormalization, Dropout"
   ],
   "id": "bc5a9ca5011959d7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:32:32.203752Z",
     "start_time": "2025-03-12T10:32:32.200723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate synthetic sine wave data\n",
    "def generate_sine_wave(seq_length, num_samples):\n",
    "    X, y = [], []\n",
    "    for _ in range(num_samples):\n",
    "        start = np.random.rand() * 2 * np.pi # Random start point\n",
    "    seq = np.array([np.sin(start + i) for i in range(seq_length + 1)])\n",
    "    X.append(seq[:-1])\n",
    "    y.append(seq[-1])\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "4c4ac79476935c9d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:32:32.230657Z",
     "start_time": "2025-03-12T10:32:32.227723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Experimenting with different sequence lengths and hidden units\n",
    "seq_lengths = [30, 50, 70]\n",
    "hidden_units = [20, 50, 100]\n",
    "num_samples = 1000\n",
    "\n",
    "def build_rnn(units, seq_length, use_improvements=False):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units, activation='tanh', return_sequences=True, input_shape=(seq_length, 1)))\n",
    "    if use_improvements:\n",
    "        model.add(BatchNormalization()) # Helps stabilize training\n",
    "        model.add(Dropout(0.2)) # Prevents overfitting\n",
    "    model.add(SimpleRNN(units, activation='tanh'))# other conditions\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ],
   "id": "62e64a1a80754e84",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T10:32:32.689067Z",
     "start_time": "2025-03-12T10:32:32.233476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for seq_length in seq_lengths:\n",
    "      for units in hidden_units:\n",
    "        print(f\"Training SimpleRNN with sequence length {seq_length} and {units} hidden units\")\n",
    "   \n",
    "        X, y = generate_sine_wave(seq_length, num_samples)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        test_size = int(0.2 * num_samples)\n",
    "        X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "        y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "        # Build standard SimpleRNN model (prone to vanishing gradients)\n",
    "        model = build_rnn(units, seq_length, use_improvements=False)\n",
    "        history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Loss Curve (SimpleRNN, Seq Length: {seq_length}, Units: {units})\")\n",
    "        plt.show()\n",
    "\n",
    "        # Evaluate model\n",
    "        predictions = model.predict(X_test)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(y_test, label='True Values', color='blue')\n",
    "        plt.plot(predictions, label='Predictions', color='orange')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(f\"True vs Predicted Values (SimpleRNN, Seq Length: {seq_length}, Units: {units})\")\n",
    "        plt.show()"
   ],
   "id": "ca272d38506bd6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SimpleRNN with sequence length 30 and 20 hidden units\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Build standard SimpleRNN model (prone to vanishing gradients)\u001B[39;00m\n\u001B[1;32m     13\u001B[0m model \u001B[38;5;241m=\u001B[39m build_rnn(units, seq_length, use_improvements\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 14\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Plot training history\u001B[39;00m\n\u001B[1;32m     17\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m4\u001B[39m))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/nn-and-dl_lab_by_rohith/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/opt/anaconda3/envs/nn-and-dl_lab_by_rohith/lib/python3.8/site-packages/keras/src/engine/training.py:1754\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1752\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m   1753\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m logs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1754\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1755\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected result of `train_function` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1756\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(Empty logs). This could be due to issues in input \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1757\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipeline that resulted in an empty dataset. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOtherwise, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1759\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minformation of where went wrong, or file a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1762\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124missue/bug to `tf.keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1763\u001B[0m     )\n\u001B[1;32m   1764\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_and_get_metrics_result(logs)\n",
      "\u001B[0;31mValueError\u001B[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Using batch normalization and dropout to mitigate vanishing gradient\n",
    "for seq_length in seq_lengths:\n",
    "      for units in hidden_units:\n",
    "        print(f\"Training Improved SimpleRNN to overcome vanishing gradient problem (Seq Length: {seq_length}, Units: {units})\")\n",
    "   \n",
    "        X, y = generate_sine_wave(seq_length, num_samples)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        test_size = int(0.2 * num_samples)\n",
    "        X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "        y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "        # Build improved RNN model\n",
    "        model = build_rnn(units, seq_length, use_improvements=True)\n",
    "        history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f\"Loss Curve (Improved SimpleRNN, Seq Length: {seq_length}, Units: {units})\")\n",
    "        plt.show()\n",
    "\n",
    "        # Evaluate model\n",
    "        predictions = model.predict(X_test)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(y_test, label='True Values', color='blue')\n",
    "        plt.plot(predictions, label='Predictions', color='orange')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Sample Index\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(f\"True vs Predicted Values (Improved SimpleRNN, Seq Length: {seq_length}, Units: {units})\")\n",
    "        plt.show()\n"
   ],
   "id": "444c6622313ec38e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
